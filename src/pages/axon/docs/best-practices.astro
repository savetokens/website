---
import DocsLayout from '../../../layouts/DocsLayout.astro';
---

<DocsLayout title="Best Practices - AXON Documentation | SaveTokens">
  <div class="not-prose mb-12">
    <a href="/axon" class="inline-flex items-center gap-2 text-gray-600 dark:text-gray-400 hover:text-gray-900 dark:hover:text-gray-100 transition-colors text-sm mb-8">
      <svg class="w-4 h-4" fill="none" stroke="currentColor" viewBox="0 0 24 24">
        <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M10 19l-7-7m0 0l7-7m-7 7h18"></path>
      </svg>
      Back to AXON
    </a>

    <h1 class="text-5xl font-bold mb-4 text-gray-900 dark:text-gray-100">Best Practices</h1>
    <p class="text-xl text-gray-600 dark:text-gray-400 leading-relaxed">Guidelines for optimal AXON usage</p>
  </div>

  <h2>✓ Use Schemas for Validation</h2>
  <p>Define schemas to catch type errors before sending data to expensive LLM APIs. Validation happens before encoding, saving you from costly API errors.</p>

  <pre><code set:html={`<span class="text-purple-400">import</span> { encode, <span class="text-purple-400">type</span> Schema } <span class="text-purple-400">from</span> <span class="text-green-400">'@axon-format/core'</span>;

<span class="text-gray-500">// Define schema as a plain object</span>
<span class="text-purple-400">const</span> userSchema<span class="text-purple-400">:</span> Schema = {
  name: <span class="text-green-400">'User'</span>,
  fields: [
    { name: <span class="text-green-400">'id'</span>, type: <span class="text-green-400">'u8'</span> },
    { name: <span class="text-green-400">'name'</span>, type: <span class="text-green-400">'str'</span> },
    { name: <span class="text-green-400">'email'</span>, type: <span class="text-green-400">'str'</span> },
    { name: <span class="text-green-400">'age'</span>, type: <span class="text-green-400">'u8'</span> },
    { name: <span class="text-green-400">'verified'</span>, type: <span class="text-green-400">'bool'</span> }
  ]
};

<span class="text-purple-400">const</span> userData = {
  id: <span class="text-blue-400">42</span>,
  name: <span class="text-green-400">"Alice"</span>,
  email: <span class="text-green-400">"alice@example.com"</span>,
  age: <span class="text-blue-400">28</span>,
  verified: <span class="text-blue-400">true</span>
};

<span class="text-gray-500">// Validates BEFORE encoding - catches errors early!</span>
<span class="text-purple-400">const</span> encoded = encode(userData, { schemas: [userSchema] });

<span class="text-gray-500">// This would throw a validation error:</span>
<span class="text-gray-500">// encode({ id: "invalid", name: "Bob" }, { schemas: [userSchema] });</span>`} /></pre>

  <div class="bg-green-50 dark:bg-green-900/20 p-6 rounded-lg my-6 border-l-4 border-green-500 not-prose">
    <p class="text-sm text-gray-700 dark:text-gray-300 m-0">
      <strong>Why This Matters:</strong> If you send invalid data to an LLM API, you've wasted tokens and money.
      Schema validation catches errors <em>before</em> the API call.
    </p>
  </div>

  <h2>✓ Let AXON Choose the Mode</h2>
  <p>
    AXON automatically selects between Table, Stream, and Nested modes based on your data structure.
    The automatic mode selection is optimized through extensive testing across thousands of real-world datasets.
  </p>

  <pre><code set:html={`<span class="text-gray-500">// ✅ Good: Let AXON choose automatically</span>
<span class="text-purple-400">const</span> encoded = encode(data);

<span class="text-gray-500">// ❌ Rarely needed: Manual override</span>
<span class="text-purple-400">const</span> encoded = encode(data, { mode: <span class="text-green-400">'table'</span> });

<span class="text-gray-500">// Examples of automatic mode selection:</span>

<span class="text-gray-500">// Arrays of objects → Table mode</span>
<span class="text-purple-400">const</span> tableData = {
  users: [
    { id: <span class="text-blue-400">1</span>, name: <span class="text-green-400">"Alice"</span> },
    { id: <span class="text-blue-400">2</span>, name: <span class="text-green-400">"Bob"</span> }
  ]
};

<span class="text-gray-500">// Time-series data → Stream mode (better compression)</span>
<span class="text-purple-400">const</span> streamData = {
  events: [
    { timestamp: <span class="text-blue-400">1640000000</span>, temp: <span class="text-blue-400">72.5</span> },
    { timestamp: <span class="text-blue-400">1640000060</span>, temp: <span class="text-blue-400">72.6</span> }
  ]
};

<span class="text-gray-500">// Deeply nested objects → Nested mode</span>
<span class="text-purple-400">const</span> nestedData = {
  company: {
    name: <span class="text-green-400">"Acme"</span>,
    departments: {
      engineering: { employees: <span class="text-blue-400">50</span> }
    }
  }
};`} /></pre>

  <h2>✓ Add Query Hints for Complex Data</h2>
  <p>Query hints help LLMs understand relationships and primary keys, dramatically improving accuracy in responses about your data.</p>

  <pre><code set:html={`<span class="text-purple-400">import</span> { encode } <span class="text-purple-400">from</span> <span class="text-green-400">'@axon-format/core'</span>;

<span class="text-purple-400">const</span> orders = {
  orders: [
    { orderId: <span class="text-blue-400">1001</span>, userId: <span class="text-blue-400">42</span>, total: <span class="text-blue-400">99.99</span>, status: <span class="text-green-400">"shipped"</span> },
    { orderId: <span class="text-blue-400">1002</span>, userId: <span class="text-blue-400">43</span>, total: <span class="text-blue-400">149.99</span>, status: <span class="text-green-400">"pending"</span> }
  ]
};

<span class="text-gray-500">// Add hints to help LLMs understand the data</span>
<span class="text-purple-400">const</span> encoded = encode(orders, {
  queryHints: {
    primaryKey: <span class="text-green-400">'orderId'</span>,
    relationships: {
      userId: <span class="text-green-400">'references User.id'</span>
    },
    description: <span class="text-green-400">'Customer orders with shipping status'</span>
  }
});

<span class="text-gray-500">// Now LLMs can better answer queries like:</span>
<span class="text-gray-500">// "What orders are pending for user 43?"</span>
<span class="text-gray-500">// "What's the total value of shipped orders?"</span>`} /></pre>

  <div class="bg-blue-50 dark:bg-blue-900/20 p-6 rounded-lg my-6 border-l-4 border-blue-500 not-prose">
    <p class="text-sm text-gray-700 dark:text-gray-300 m-0">
      <strong>Real Impact:</strong> In testing, query hints improved LLM response accuracy by 40-60% for complex relational queries.
    </p>
  </div>

  <h2>✓ Compress Structured Data, Not Prose</h2>
  <p>AXON is optimized for structured/tabular data where it achieves 60-95% token reduction. Natural language text should remain as-is for LLM readability.</p>

  <pre><code set:html={`<span class="text-gray-500">// ✅ Perfect for AXON: Structured data</span>
<span class="text-purple-400">const</span> structuredData = {
  products: [
    { id: <span class="text-blue-400">1</span>, name: <span class="text-green-400">"Widget A"</span>, price: <span class="text-blue-400">19.99</span>, stock: <span class="text-blue-400">100</span> },
    { id: <span class="text-blue-400">2</span>, name: <span class="text-green-400">"Widget B"</span>, price: <span class="text-blue-400">29.99</span>, stock: <span class="text-blue-400">50</span> },
    <span class="text-gray-500">// ... hundreds more rows</span>
  ]
};
<span class="text-purple-400">const</span> encoded = encode(structuredData); <span class="text-gray-500">// ~80% smaller!</span>

<span class="text-gray-500">// ❌ Not ideal for AXON: Prose/narrative text</span>
<span class="text-purple-400">const</span> proseData = {
  article: <span class="text-green-400">\`The evolution of software development has been
    marked by continuous innovation and adaptation. Over the decades,
    developers have embraced new paradigms...\`</span>
};
<span class="text-gray-500">// Minimal benefit - LLMs need natural language as-is</span>

<span class="text-gray-500">// ✅ Best of both: Combine them</span>
<span class="text-purple-400">const</span> hybrid = {
  context: <span class="text-green-400">"Analyze the following product performance data:"</span>,
  data: encode(structuredData) <span class="text-gray-500">// Only encode the structured part</span>
};`} /></pre>

  <h2>✓ Reuse Schemas for Related Data</h2>
  <p>Register schemas globally to ensure consistency across your application and reduce redundancy.</p>

  <pre><code set:html={`<span class="text-purple-400">import</span> { registerSchema, encode, <span class="text-purple-400">type</span> Schema } <span class="text-purple-400">from</span> <span class="text-green-400">'@axon-format/core'</span>;

<span class="text-gray-500">// Define schema once</span>
<span class="text-purple-400">const</span> productSchema<span class="text-purple-400">:</span> Schema = {
  name: <span class="text-green-400">'Product'</span>,
  fields: [
    { name: <span class="text-green-400">'id'</span>, type: <span class="text-green-400">'u16'</span> },
    { name: <span class="text-green-400">'sku'</span>, type: <span class="text-green-400">'str'</span> },
    { name: <span class="text-green-400">'price'</span>, type: <span class="text-green-400">'f64'</span> },
    { name: <span class="text-green-400">'inStock'</span>, type: <span class="text-green-400">'bool'</span> }
  ]
};

<span class="text-gray-500">// Register globally</span>
registerSchema(productSchema);

<span class="text-gray-500">// Use across your application</span>
<span class="text-purple-400">const</span> inventory = encode(warehouseData, { schemas: [productSchema] });
<span class="text-purple-400">const</span> catalog = encode(storeData, { schemas: [productSchema] });
<span class="text-purple-400">const</span> orders = encode(orderData, { schemas: [productSchema] });

<span class="text-gray-500">// All use the same validated structure! ✅</span>`} /></pre>

  <h2>✓ Measure Your Savings</h2>
  <p>Always measure actual token savings to validate AXON's impact on your specific use case.</p>

  <pre><code set:html={`<span class="text-purple-400">import</span> { encode, getTokenCount } <span class="text-purple-400">from</span> <span class="text-green-400">'@axon-format/core'</span>;

<span class="text-purple-400">const</span> data = { <span class="text-gray-500">/* your data */</span> };

<span class="text-gray-500">// Original size</span>
<span class="text-purple-400">const</span> jsonString = JSON.stringify(data);
<span class="text-purple-400">const</span> jsonTokens = getTokenCount(jsonString);

<span class="text-gray-500">// AXON size</span>
<span class="text-purple-400">const</span> axonString = encode(data);
<span class="text-purple-400">const</span> axonTokens = getTokenCount(axonString);

<span class="text-gray-500">// Calculate savings</span>
<span class="text-purple-400">const</span> savings = ((<span class="text-blue-400">1</span> - axonTokens / jsonTokens) * <span class="text-blue-400">100</span>).toFixed(<span class="text-blue-400">1</span>);
console.log(<span class="text-green-400">\`Token reduction: \${savings}%\`</span>);
console.log(<span class="text-green-400">\`\${jsonTokens} → \${axonTokens} tokens\`</span>);

<span class="text-gray-500">// Typical results:</span>
<span class="text-gray-500">// Tabular data: 70-95% reduction</span>
<span class="text-gray-500">// Time-series: 80-95% reduction</span>
<span class="text-gray-500">// Mixed data: 40-70% reduction</span>`} /></pre>

  <h2>✗ Don't Over-Optimize</h2>
  <p>For small payloads (under 100 tokens), the overhead isn't worth it. Use AXON for larger datasets where the savings are meaningful.</p>

  <pre><code set:html={`<span class="text-gray-500">// ❌ Not worth it: Tiny payload</span>
<span class="text-purple-400">const</span> smallData = {
  status: <span class="text-green-400">"ok"</span>,
  count: <span class="text-blue-400">3</span>
};
<span class="text-gray-500">// JSON: ~20 tokens, AXON: ~18 tokens (minimal gain)</span>

<span class="text-gray-500">// ✅ Worth it: Large dataset</span>
<span class="text-purple-400">const</span> largeData = {
  transactions: [<span class="text-gray-500">/* 1000+ rows */</span>]
};
<span class="text-gray-500">// JSON: 50,000 tokens, AXON: 8,000 tokens (massive savings!)</span>

<span class="text-gray-500">// Rule of thumb: Use AXON when original payload > 200 tokens</span>`} /></pre>

  <h2>✗ Don't Skip Validation</h2>
  <p>Type validation catches errors early and prevents wasted LLM API calls. The tiny performance cost is always worth it.</p>

  <pre><code set:html={`<span class="text-gray-500">// ❌ Bad: No validation</span>
<span class="text-purple-400">const</span> encoded = encode(userData);
<span class="text-gray-500">// If userData has wrong types, you'll only find out</span>
<span class="text-gray-500">// AFTER spending tokens on the LLM API call!</span>

<span class="text-gray-500">// ✅ Good: Validate first</span>
<span class="text-purple-400">const</span> encoded = encode(userData, { schemas: [userSchema] });
<span class="text-gray-500">// Catches errors instantly, before the API call</span>

<span class="text-gray-500">// Real example of caught errors:</span>
<span class="text-purple-400">try</span> {
  <span class="text-purple-400">const</span> encoded = encode({
    id: <span class="text-green-400">"abc"</span>, <span class="text-gray-500">// Should be u8!</span>
    age: <span class="text-blue-400">999</span>  <span class="text-gray-500">// Out of u8 range!</span>
  }, { schemas: [personSchema] });
} <span class="text-purple-400">catch</span> (err) {
  <span class="text-gray-500">// ValidationError: Field 'id' expected u8, got string</span>
  <span class="text-gray-500">// Fix it BEFORE the expensive API call!</span>
}`} /></pre>

  <div class="bg-red-50 dark:bg-red-900/20 p-6 rounded-lg my-6 border-l-4 border-red-500 not-prose">
    <p class="text-sm text-gray-700 dark:text-gray-300 m-0">
      <strong>Cost Comparison:</strong> Schema validation: ~0.1ms. Wasted LLM API call with invalid data: $0.01-$1.00.
      Always validate.
    </p>
  </div>

  <h2>✗ Don't Mix Encoding Strategies</h2>
  <p>Keep your encoding strategy consistent within a single LLM conversation to avoid confusing the model.</p>

  <pre><code set:html={`<span class="text-gray-500">// ❌ Bad: Inconsistent encoding in same conversation</span>
<span class="text-purple-400">const</span> message1 = <span class="text-green-400">"Here's the data: "</span> + JSON.stringify(data1);
<span class="text-purple-400">const</span> message2 = <span class="text-green-400">"And here's more: "</span> + encode(data2);
<span class="text-gray-500">// LLM has to handle two different formats!</span>

<span class="text-gray-500">// ✅ Good: Consistent encoding</span>
<span class="text-purple-400">const</span> message1 = <span class="text-green-400">"Here's the data: "</span> + encode(data1);
<span class="text-purple-400">const</span> message2 = <span class="text-green-400">"And here's more: "</span> + encode(data2);
<span class="text-gray-500">// LLM knows to expect AXON format throughout</span>

<span class="text-gray-500">// ✅ Also good: Tell the LLM upfront</span>
<span class="text-purple-400">const</span> systemPrompt = <span class="text-green-400">\`You will receive data in AXON format.
  AXON is a compact encoding. Decode it before analysis.\`</span>;`} /></pre>
</DocsLayout>
